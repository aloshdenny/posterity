{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Convert Chats to '.TXT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified speakers: ['Joachii🐧', 'joe']\n",
      "Processed 10651 messages\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define regex patterns\n",
    "timestamp_pattern = r'^\\d{1,2}/\\d{1,2}/\\d{4},\\s\\d{1,2}:\\d{2}\\s[ap]m\\s-\\s'\n",
    "link_pattern = r'(https?://|www\\.)\\S+'\n",
    "edited_message_pattern = r' <This message was edited>'\n",
    "deleted_message_pattern = r'This message was deleted'\n",
    "speaker_detection_pattern = r'^(.*?):\\s'  # We'll improve how we use this\n",
    "you_deleted_this_message_pattern = r'You deleted this message'\n",
    "\n",
    "# Read input file\n",
    "with open('/Users/aloshdenny/Downloads/WhatsApp Chat with Joachii🐧/WhatsApp Chat with Joachii🐧.txt', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# First pass: identify the two speakers\n",
    "potential_speakers = []\n",
    "for line in lines:\n",
    "    # Skip lines without timestamp (continuation lines)\n",
    "    if not re.match(timestamp_pattern, line):\n",
    "        continue\n",
    "        \n",
    "    # Extract potential speaker\n",
    "    line_without_timestamp = re.sub(timestamp_pattern, '', line).strip()\n",
    "    speaker_match = re.match(speaker_detection_pattern, line_without_timestamp)\n",
    "    if speaker_match:\n",
    "        speaker = speaker_match.group(1)\n",
    "        # Avoid capturing things like \"Ps:\" within a message\n",
    "        if len(speaker) < 30 and \":\" not in speaker:  # Reasonable length for a name\n",
    "            potential_speakers.append(speaker)\n",
    "\n",
    "# Find the two most common potential speakers\n",
    "speaker_counts = {}\n",
    "for speaker in potential_speakers:\n",
    "    if speaker in speaker_counts:\n",
    "        speaker_counts[speaker] += 1\n",
    "    else:\n",
    "        speaker_counts[speaker] = 1\n",
    "\n",
    "# Sort speakers by frequency\n",
    "sorted_speakers = sorted(speaker_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "valid_speakers = [speaker for speaker, count in sorted_speakers[:2]]\n",
    "\n",
    "print(f\"Identified speakers: {valid_speakers}\")\n",
    "\n",
    "# Second pass: extract messages\n",
    "messages = []\n",
    "continuation = False\n",
    "current_message = None\n",
    "\n",
    "for line in lines:\n",
    "    # Check if this is a new message with timestamp\n",
    "    if re.match(timestamp_pattern, line):\n",
    "        # Process the previous message if there was one\n",
    "        if current_message is not None:\n",
    "            messages.append(current_message)\n",
    "            \n",
    "        # Remove timestamp\n",
    "        line_without_timestamp = re.sub(timestamp_pattern, '', line).strip()\n",
    "        \n",
    "        # Skip lines with unwanted content\n",
    "        if ('Media omitted' in line_without_timestamp or \n",
    "            'null' in line_without_timestamp or \n",
    "            re.search(link_pattern, line_without_timestamp) or \n",
    "            re.search(deleted_message_pattern, line_without_timestamp) or\n",
    "            re.search(you_deleted_this_message_pattern, line_without_timestamp)):  # Add this line\n",
    "            current_message = None\n",
    "            continuation = False\n",
    "            continue\n",
    "            \n",
    "        # Remove edited message indicator\n",
    "        line_without_timestamp = re.sub(edited_message_pattern, '', line_without_timestamp).strip()\n",
    "        \n",
    "        # Check word count\n",
    "        if len(line_without_timestamp.split()) > 100:\n",
    "            current_message = None\n",
    "            continuation = False\n",
    "            continue\n",
    "            \n",
    "        # Identify speaker\n",
    "        speaker_match = re.match(speaker_detection_pattern, line_without_timestamp)\n",
    "        if speaker_match:\n",
    "            potential_speaker = speaker_match.group(1)\n",
    "            if potential_speaker in valid_speakers:\n",
    "                speaker = potential_speaker\n",
    "                message_text = line_without_timestamp[len(speaker)+2:].strip()\n",
    "                current_message = {'speaker': speaker, 'text': message_text}\n",
    "                continuation = True\n",
    "            else:\n",
    "                # If it's not a valid speaker, it might be a message with a colon\n",
    "                unknown_speaker_found = False\n",
    "                for valid_speaker in valid_speakers:\n",
    "                    if line_without_timestamp.startswith(valid_speaker + \": \"):\n",
    "                        speaker = valid_speaker\n",
    "                        message_text = line_without_timestamp[len(speaker)+2:].strip()\n",
    "                        current_message = {'speaker': speaker, 'text': message_text}\n",
    "                        continuation = True\n",
    "                        unknown_speaker_found = True\n",
    "                        break\n",
    "                \n",
    "                if not unknown_speaker_found:\n",
    "                    current_message = None\n",
    "                    continuation = False\n",
    "        else:\n",
    "            current_message = None\n",
    "            continuation = False\n",
    "    \n",
    "    # If this is a continuation line (no timestamp)\n",
    "    elif continuation and current_message is not None:\n",
    "        current_message['text'] += \" \" + line.strip()\n",
    "\n",
    "# Add the last message if there is one\n",
    "if current_message is not None:\n",
    "    messages.append(current_message)\n",
    "\n",
    "# Concatenate consecutive messages from the same speaker\n",
    "concatenated_messages = []\n",
    "prev_speaker = None\n",
    "buffer_text = \"\"\n",
    "\n",
    "for msg in messages:\n",
    "    if msg['speaker'] == prev_speaker:\n",
    "        buffer_text += \". \" + msg['text']\n",
    "    else:\n",
    "        if prev_speaker is not None:\n",
    "            concatenated_messages.append({'speaker': prev_speaker, 'text': buffer_text})\n",
    "        prev_speaker = msg['speaker']\n",
    "        buffer_text = msg['text']\n",
    "\n",
    "# Append the last buffered message\n",
    "if prev_speaker is not None:\n",
    "    concatenated_messages.append({'speaker': prev_speaker, 'text': buffer_text})\n",
    "\n",
    "# Save parsed messages to a text file\n",
    "with open('/Users/aloshdenny/Downloads/WhatsApp Chat with Joachii🐧/updated.txt', 'w', encoding='utf-8') as file:\n",
    "    for msg in concatenated_messages:\n",
    "        file.write(f\"{msg['speaker']}: {msg['text']}\\n\")\n",
    "\n",
    "print(f\"Processed {len(concatenated_messages)} messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 1: joe\n",
      "Speaker 2: Joachii🐧\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Path to the updated text file\n",
    "input_file = '/Users/aloshdenny/Downloads/WhatsApp Chat with Joachii🐧/updated.txt'\n",
    "output_file = '/Users/aloshdenny/Downloads/WhatsApp Chat with Joachii🐧/conversation.csv'\n",
    "\n",
    "# Read the file\n",
    "with open(input_file, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Extract messages with speakers\n",
    "messages = []\n",
    "for line in lines:\n",
    "    match = re.match(r'^(.*?):\\s(.*)$', line.strip())\n",
    "    if match:\n",
    "        speaker = match.group(1)\n",
    "        text = match.group(2)\n",
    "        messages.append({'speaker': speaker, 'text': text})\n",
    "\n",
    "# Identify the two speakers\n",
    "speakers = list(set([msg['speaker'] for msg in messages]))\n",
    "\n",
    "if len(speakers) != 2:\n",
    "    print(f\"Warning: Found {len(speakers)} speakers instead of 2. Using the first two speakers found.\")\n",
    "    speakers = speakers[:2]\n",
    "\n",
    "speaker1 = speakers[0]\n",
    "speaker2 = speakers[1]\n",
    "\n",
    "print(f\"Speaker 1: {speaker1}\")\n",
    "print(f\"Speaker 2: {speaker2}\")\n",
    "\n",
    "# Initialize conversation dataframe\n",
    "conversation = []\n",
    "current_row = {speaker1: \"\", speaker2: \"\"}\n",
    "last_speaker = None\n",
    "\n",
    "for msg in messages:\n",
    "    current_speaker = msg['speaker']\n",
    "    \n",
    "    # Skip speakers that aren't one of our main two (if there are more than 2)\n",
    "    if current_speaker not in [speaker1, speaker2]:\n",
    "        continue\n",
    "    \n",
    "    # If the same speaker speaks again, append to their previous message\n",
    "    if current_speaker == last_speaker:\n",
    "        current_row[current_speaker] += \" \" + msg['text']\n",
    "    # If the other speaker starts talking\n",
    "    elif last_speaker is not None and current_speaker != last_speaker:\n",
    "        # If we have messages from both speakers, save the row and start a new one\n",
    "        if current_row[speaker1] and current_row[speaker2]:\n",
    "            conversation.append(current_row)\n",
    "            current_row = {speaker1: \"\", speaker2: \"\"}\n",
    "        \n",
    "        # Add the current message to the appropriate column\n",
    "        current_row[current_speaker] = msg['text']\n",
    "    # First message in the conversation\n",
    "    else:\n",
    "        current_row[current_speaker] = msg['text']\n",
    "    \n",
    "    last_speaker = current_speaker\n",
    "\n",
    "# Add the last row if it has content\n",
    "if current_row[speaker1] or current_row[speaker2]:\n",
    "    conversation.append(current_row)\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "df = pd.DataFrame(conversation)\n",
    "df.to_csv(output_file, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Gemini STT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The session just got over and everyone is so happy with it, including me. So fun. Honey, I loved it, man. They all came up to me saying enjoy, Chechi. I have never had such a fun session. There was no such a mental session. I'm so happy. I'm so happy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key='AIzaSyDhjCyGvC9_EMJXBME28KRwm110qlbJZCg')\n",
    "\n",
    "myfile = client.files.upload(file=r\"C:\\Users\\alosh\\Downloads\\WhatsApp Chat with Joachii\\PTT-20250308-WA0020.opus\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "  model='gemini-2.0-flash',\n",
    "  contents=['Translate this audio clip to English, word for word', myfile]\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk STT from Audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from google import genai\n",
    "\n",
    "# Initialize the client\n",
    "client = genai.Client(api_key='AIzaSyDhjCyGvC9_EMJXBME28KRwm110qlbJZCg')\n",
    "\n",
    "# Define the directory where .opus files are located\n",
    "directory = r\"C:\\Users\\alosh\\Downloads\\WhatsApp Chat with Joachii\"\n",
    "\n",
    "# Initialize a dictionary to store the transcriptions\n",
    "transcriptions_dict = {}\n",
    "\n",
    "# Open the JSON output file with UTF-8 encoding\n",
    "with open('joanne.json', 'w', encoding='utf-8') as json_file:\n",
    "    \n",
    "    # Loop through each file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".opus\"):  # Check if the file is an .opus file\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            \n",
    "            # Upload the .opus file\n",
    "            myfile = client.files.upload(file=file_path)\n",
    "            \n",
    "            # Send the file to the model for transcription\n",
    "            response = client.models.generate_content(\n",
    "                model='gemini-2.0-flash',\n",
    "                contents=['Translate this audio clip to English, word for word', myfile]\n",
    "            )\n",
    "            \n",
    "            # Save the transcription in the dictionary using the filename as the key\n",
    "            transcriptions_dict[filename] = response.text\n",
    "            \n",
    "            # Print the result to the console (optional)\n",
    "            print(f\"Transcription for {filename}:\")\n",
    "            print(response.text)\n",
    "            print(\"\\n\")\n",
    "\n",
    "    # After all transcriptions are done, write the dictionary to the JSON file with UTF-8 encoding\n",
    "    json.dump(transcriptions_dict, json_file, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superfloat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
